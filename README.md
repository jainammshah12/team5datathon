# Regulatory Impact Analyzer

AI-powered tool that analyzes regulatory documents and evaluates their financial impact on S&P 500 companies.

## Team Members
- Jainam Shah 
- Hubert Lefebvre 
- Jose Del Portillo Neira 
- Bhavya Ruparelia

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure AWS S3
Create `.env` file with your AWS credentials:
```env
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_SESSION_TOKEN=your_session_token  # Required for temporary credentials (ASIA*)
AWS_DEFAULT_REGION=us-west-2
S3_BUCKET_NAME=your-bucket-name
```

**Note:** If your Access Key starts with `ASIA`, you need the session token. Get it with:
```bash
aws configure export-credentials --profile default
```

### 3. Launch Application
```bash
python gradio_app.py
```
Access at: **http://localhost:7860**

## ğŸ“‹ Features

### ğŸ“„ Document Management
- **Upload** regulatory documents (.html, .xml, .txt, .md) to S3
- **Automatic overwrite** - Duplicate files are replaced automatically
- **Auto-load** - Uploaded documents load immediately
- **Full text view** - Complete document text (no truncation)
- All documents stored in S3 bucket at `data/directives/`

### ğŸ” Analysis (Placeholder)
- Extract entities from regulatory documents
- Evaluate financial impact on S&P 500 companies
- Identify affected sectors and companies
- *Note: LLM integration pending - implement in `llm/llm_client.py`*

### ğŸ’¼ Portfolio (Placeholder)
- Portfolio adjustment recommendations
- Financial impact simulations
- Risk assessment
- *Note: Requires LLM implementation*

### ğŸ“Š Data Explorer
- S&P 500 company composition
- Stock performance data
- All data from S3 bucket

## ğŸ—ï¸ Architecture

```
gradio_app.py           # Main Gradio interface
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ s3_utils.py     # S3 operations (read/write/delete)
â”‚   â””â”€â”€ document_processor.py  # Text extraction & cleaning
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ instructions.json      # LLM prompts & formats
â”‚   â””â”€â”€ llm_client.py         # LLM API client (TODO: implement)
â””â”€â”€ templates/
    â”œâ”€â”€ custom.css     # UI styling
    â””â”€â”€ custom.html    # HTML templates
```

## ğŸ”‘ AWS Permissions Required

Your IAM user/role needs:
- `s3:ListBucket` - List files in bucket
- `s3:GetObject` - Read files
- `s3:PutObject` - Upload files
- `s3:DeleteObject` - Delete/replace files

## ğŸ’¡ Usage

1. **Upload Document**: Select file â†’ Click "ğŸ“¤ Upload to S3" â†’ Auto-loads
2. **View Document**: Select from dropdown â†’ Click "Load Selected Document"
3. **Refresh List**: Click "ğŸ”„ Refresh Document List" after external changes
4. **Analyze** (when LLM implemented): Load document â†’ Click analysis buttons

## ğŸ› ï¸ Tech Stack

- **Frontend**: Gradio 4.0+
- **Storage**: AWS S3
- **Backend**: Python 3.8+, Boto3
- **Processing**: BeautifulSoup4, Pandas
- **AI/LLM**: Perplexity/OpenAI API (to be configured)

## ğŸ“ Data Structure in S3

```
s3://your-bucket/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ directives/              # Regulatory documents
â”‚   â”œâ”€â”€ fillings/                # Company 10-K filings
â”‚   â”‚   â”œâ”€â”€ AAPL/
â”‚   â”‚   â”œâ”€â”€ MSFT/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ 2025-08-15_composition_sp500.csv
â”‚   â””â”€â”€ 2025-09-26_stocks-performance.csv
```

## ğŸ”§ Next Steps

1. **Implement LLM Integration** - Add API calls in `llm/llm_client.py`
2. **Add Error Handling** - Improve validation and error messages
3. **Enhance Analysis** - Connect analysis buttons to LLM functions
4. **Add Caching** - Cache processed documents in S3
5. **Add Visualizations** - Charts for impact analysis
